# ===================================================================
# OÃ™ S'INSTALLENT LES MODÃˆLES ?
# ===================================================================
# Par dÃ©faut, les emplacements sont :
# Dans la VM Ubuntu

# 1. Ollama (LLMs locaux)
# --> ~/.ollama/models/
# ou
# --> /usr/share/ollama/.ollama/models/

# 2. Hugging Face (transformers, diffusers)
# --> ~/.cache/huggingface/
# --> â””â”€â”€ hub/  # ModÃ¨les tÃ©lÃ©chargÃ©s

# 3. Stable Diffusion (Automatic1111)
# --> ~/stable-diffusion-webui/models/
# --> â”œâ”€â”€ Stable-diffusion/
# --> â”œâ”€â”€ VAE/
# --> â”œâ”€â”€ Lora/
# --> â””â”€â”€ embeddings/

# 4. PyTorch/TensorFlow (modÃ¨les prÃ©-entraÃ®nÃ©s)
# --> ~/.cache/torch/hub/
# --> ~/.keras/models/

# VÃ©rifier l'emplacement actuel
# Dans la VM
# Ollama
ollama list  # Liste les modÃ¨les
sudo du -sh ~/.ollama/models/ 2>/dev/null
sudo du -sh /usr/share/ollama/.ollama/models/ 2>/dev/null

# Hugging Face
sudo du -sh ~/.cache/huggingface/

# Stable Diffusion
sudo du -sh ~/stable-diffusion-webui/models/

# ===================================================================
# Les modÃ¨les doivent-ils Ãªtre sur NVMe ?
# ===================================================================
# Non, pas obligatoirement.
#  - Chargement initial : Un modÃ¨le de 7GB prend ~35s depuis HDD vs ~1s depuis NVMe
#  - Une fois en RAM : Aucune diffÃ©rence de performance
#  - Recommandation :
#     - ModÃ¨les utilisÃ©s quotidiennement : NVMe
#     - ModÃ¨les occasionnels : HDD (acceptable)

# ===================================================================
# Ã€ quoi sert le stockage HDD partagÃ© ?
# ===================================================================
# 1.BibliothÃ¨que de modÃ¨les : Stocker 50+ modÃ¨les diffÃ©rents
# 2.Datasets volumineux : ImageNet (150GB), Common Crawl, etc.
# 3.Partage entre VMs : AccÃ¨s depuis toutes vos VMs
# 4.Backups : Projets, modÃ¨les fine-tunÃ©s
# 5.Archives : Anciennes versions de modÃ¨les
# 6.Ã‰conomie NVMe : Garder 280G libres sur NVMe pour l'OS et le cache

# ðŸ“ˆ Calcul d'espace typique
# Sur NVMe (VM 350G) :
#  - OS Ubuntu : 15G
#  - Environnements Python : 10G
#  - Cache temporaire : 20G
#  - ModÃ¨les actifs : 50G
#  - Espace libre : 255G âœ…

# Sur HDD partagÃ© (1To) :
#  - ModÃ¨les archivÃ©s : 200G
#  - Datasets : 400G
#  - Backups projets : 100G
#  - Espace libre : 300G âœ…

Vous avez maintenant une architecture flexible et Ã©volutive ! Le HDD sert de "bibliothÃ¨que" et le NVMe de "bureau de travail".

# ===================================================================
# NVMe vs HDD : Quelle diffÃ©rence ?
# ===================================================================
# NVMe (Corsair MP700 Pro) - RAPIDE âš¡
#  - Lecture : 12,400 MB/s
#  - Latence : < 1ms
#  - Usage : Chargement rapide des modÃ¨les en RAM

# HDD (WD Red) - CAPACITÃ‰ ðŸ“¦
#  - Lecture : ~200 MB/s (60x plus lent)
#  - Latence : 10-15ms
#  - Usage : Stockage de masse, archives

# ===================================================================
# STRATÃ‰GIE RECOMMANDÃ‰E
# ===================================================================
# Ce qui DOIT Ãªtre sur NVMe (dans la VM) :
# âœ… ModÃ¨les utilisÃ©s quotidiennement
#  - Ollama : modÃ¨les actifs (llama, mistral)
#  - Hugging Face : modÃ¨les en cours d'utilisation
#  - Stable Diffusion : modÃ¨le principal

# âœ… Datasets en cours de traitement
#  - Images pour entraÃ®nement actif
#  - DonnÃ©es prÃ©-traitÃ©es

# âœ… Checkpoints d'entraÃ®nement
#  - Sauvegardes pendant le fine-tuning

# Ce qui VA sur HDD (stockage partagÃ©) :
# ðŸ“¦ Archive des modÃ¨les
#  - Anciens modÃ¨les peu utilisÃ©s
#  - DiffÃ©rentes versions de modÃ¨les
#  - ModÃ¨les de test

# ðŸ“¦ Datasets volumineux
#  - ImageNet complet
#  - Datasets bruts non traitÃ©s
#  - Archives de datasets

# ðŸ“¦ Backups
#  - Sauvegardes de projets
#  - Exports de modÃ¨les fine-tunÃ©s

# ===================================================================
# CONFIGURATION OPTIMALE
# ===================================================================
# 1. DÃ©placer le cache Ollama vers le stockage partagÃ©
# Dans la VM
# ===================================================================
# CrÃ©er un dossier pour les modÃ¨les partagÃ©s
sudo mkdir -p /mnt/shared/models/ollama

# ArrÃªter Ollama
sudo systemctl stop ollama

# Configurer Ollama pour utiliser le stockage partagÃ©
sudo mkdir -p /etc/systemd/system/ollama.service.d
sudo nano /etc/systemd/system/ollama.service.d/override.conf
# Contenu :
[Service]
Environment="OLLAMA_MODELS=/mnt/shared/models/ollama"

# Recharger et redÃ©marrer
sudo systemctl daemon-reload
sudo systemctl start ollama

# VÃ©rifier
ollama list
ls -lh /mnt/shared/models/ollama/
# ===================================================================
# OU crÃ©er un lien symbolique (plus simple) :
# ArrÃªter Ollama
sudo systemctl stop ollama

# DÃ©placer les modÃ¨les existants
sudo mv ~/.ollama/models/* /mnt/shared/models/ollama/ 2>/dev/null

# CrÃ©er le lien
rm -rf ~/.ollama/models
ln -s /mnt/shared/models/ollama ~/.ollama/models

# RedÃ©marrer
sudo systemctl start ollama

# ===================================================================
# 2. Configurer Hugging Face pour le stockage partagÃ©
# Dans la VM
# CrÃ©er la structure
mkdir -p /mnt/shared/models/huggingface

# DÃ©finir la variable d'environnement
echo 'export HF_HOME=/mnt/shared/models/huggingface' >> ~/.bashrc
echo 'export TRANSFORMERS_CACHE=/mnt/shared/models/huggingface' >> ~/.bashrc
source ~/.bashrc

# Tester
python3 -c "import os; print(os.environ.get('HF_HOME'))"

# ===================================================================
# 3. Organisation du stockage partagÃ©
# Structure recommandÃ©e sur /mnt/shared/

# /mnt/shared/
# â”œâ”€â”€ datasets/                    # 500G sur HDD
# â”‚   â”œâ”€â”€ images/
# â”‚   â”‚   â”œâ”€â”€ imagenet/          # Datasets volumineux
# â”‚   â”‚   â”œâ”€â”€ coco/
# â”‚   â”‚   â””â”€â”€ custom/
# â”‚   â”œâ”€â”€ text/
# â”‚   â”‚   â”œâ”€â”€ wikipedia/
# â”‚   â”‚   â””â”€â”€ common-crawl/
# â”‚   â””â”€â”€ audio/
# â”‚       â””â”€â”€ librispeech/
# â”‚
# â””â”€â”€ models/                      # 500G sur HDD
#     â”œâ”€â”€ ollama/                 # ModÃ¨les LLM
#     â”‚   â”œâ”€â”€ llama-3.2-3b/
#     â”‚   â”œâ”€â”€ mistral-7b/
#     â”‚   â””â”€â”€ archived/           # Anciens modÃ¨les
#     â”œâ”€â”€ huggingface/            # Cache HF
#     â”‚   â””â”€â”€ hub/
#     â”œâ”€â”€ stable-diffusion/       # ModÃ¨les SD
#     â”‚   â”œâ”€â”€ checkpoints/
#     â”‚   â”œâ”€â”€ lora/
#     â”‚   â””â”€â”€ vae/
#     â””â”€â”€ custom/                 # Vos modÃ¨les fine-tunÃ©s
#         â”œâ”€â”€ sentiment-analysis/
#         â””â”€â”€ image-classifier/

# ===================================================================
# 4. Workflow optimal : NVMe comme cache
# IdÃ©e : Copier temporairement sur NVMe pour l'utilisation, archiver sur HDD.
# CrÃ©er un script /usr/local/bin/model-manager.sh dans la VM :

nano /usr/local/bin/model-manager.sh

#!/bin/bash
# model-manager.sh - Gestionnaire de modÃ¨les intelligent

NVME_MODELS="$HOME/models-active"  # Sur la VM (NVMe)
HDD_MODELS="/mnt/shared/models"     # Sur HDD partagÃ©

mkdir -p "$NVME_MODELS"

case "$1" in
    load)
        # Copier un modÃ¨le du HDD vers NVMe
        MODEL="$2"
        if [ -z "$MODEL" ]; then
            echo "Usage: $0 load <model-name>"
            exit 1
        fi

        echo "Copie de $MODEL depuis HDD vers NVMe..."
        rsync -avh --progress "$HDD_MODELS/$MODEL" "$NVME_MODELS/"
        echo "âœ“ ModÃ¨le disponible : $NVME_MODELS/$MODEL"
        ;;

    archive)
        # DÃ©placer un modÃ¨le de NVMe vers HDD
        MODEL="$2"
        if [ -z "$MODEL" ]; then
            echo "Usage: $0 archive <model-name>"
            exit 1
        fi

        echo "Archive de $MODEL vers HDD..."
        rsync -avh --progress "$NVME_MODELS/$MODEL" "$HDD_MODELS/"
        rm -rf "$NVME_MODELS/$MODEL"
        echo "âœ“ ModÃ¨le archivÃ© : $HDD_MODELS/$MODEL"
        ;;

    list-active)
        echo "=== ModÃ¨les sur NVMe (actifs) ==="
        du -sh "$NVME_MODELS"/* 2>/dev/null || echo "Aucun modÃ¨le actif"
        ;;

    list-archived)
        echo "=== ModÃ¨les sur HDD (archivÃ©s) ==="
        du -sh "$HDD_MODELS"/* 2>/dev/null
        ;;

    sync)
        echo "Synchronisation NVMe â†’ HDD..."
        rsync -avh --progress "$NVME_MODELS/" "$HDD_MODELS/backup-nvme/"
        echo "âœ“ Sauvegarde terminÃ©e"
        ;;

    *)
        echo "Usage: $0 {load|archive|list-active|list-archived|sync} [model-name]"
        exit 1
        ;;
esac

chmod +x /usr/local/bin/model-manager.sh

# Utilisation :
# Lister les modÃ¨les archivÃ©s
model-manager.sh list-archived

# Charger un modÃ¨le sur NVMe pour utilisation
model-manager.sh load stable-diffusion/sd-xl-base

# AprÃ¨s utilisation, archiver
model-manager.sh archive stable-diffusion/sd-xl-base

# Sauvegarder tout
model-manager.sh sync

# ===================================================================
# ðŸ“Š EXEMPLES CONCRETS
# ===================================================================
# Exemple 1 : Fine-tuning d'un modÃ¨le
# 1. Dataset sur HDD (stockage permanent)
DATASET="/mnt/shared/datasets/custom/product-reviews"

# 2. Copier un subset sur NVMe pour l'entraÃ®nement (performance)
cp -r "$DATASET" ~/training-data/

# 3. Charger le modÃ¨le de base depuis HDD
python3 << EOF
from transformers import AutoModel
import os

# Cache sur HDD
os.environ['HF_HOME'] = '/mnt/shared/models/huggingface'

model = AutoModel.from_pretrained('bert-base-uncased')
EOF

# 4. Fine-tuning (utilise la RAM)
# ...

# 5. Sauvegarder le modÃ¨le fine-tunÃ© sur HDD
cp -r ~/my-model /mnt/shared/models/custom/product-sentiment/

# ===================================================================
# Exemple 2 : GÃ©nÃ©ration d'images batch
# 1. ModÃ¨le SD sur HDD
SD_MODEL="/mnt/shared/models/stable-diffusion/sd-xl-base"

# 2. Script de gÃ©nÃ©ration pointe vers HDD
cd ~/stable-diffusion-webui
./webui.sh --ckpt "$SD_MODEL/model.safetensors"

# 3. Images gÃ©nÃ©rÃ©es sauvegardÃ©es sur HDD
OUTPUT="/mnt/shared/datasets/generated-images"






















