
# 1. STRATÉGIE DE STOCKAGE POUR VM-IA

# Corsair MP700 Pro 2To (NVMe PCIe 5.0) : Performances exceptionnelles
# 3x WD Red 4To (SATA) : Stockage de masse fiable
# Architecture recommandée :
# - Système VM + environnements Python : NVMe (rapide)
# - Datasets volumineux : WD Red en pool (capacité)
# - Modèles entraînés : WD Red en pool (sauvegarde)
#```

### Dimensionnement précis

#Breakdown typique :
#- Système Ubuntu : 10-15 GB
#- Environnements Python (venv) : 5-10 GB
#- Jupyter + notebooks : 2-5 GB
#- Cache pip/conda : 3-5 GB
#- Modèles pré-entraînés :
#  * LLaMA 7B : ~13 GB
#  * LLaMA 13B : ~26 GB
#  * Stable Diffusion XL : ~12 GB
#  * Mistral 7B : ~14 GB
#  * Whisper Large : ~3 GB
#- Datasets typiques :
#  * ImageNet subset : 20-50 GB
#  * Common Crawl sample : 10-100 GB
#  * Datasets personnalisés : Variable
#- Checkpoints d'entraînement : 10-50 GB par projet



# Configuration du stockage partagé sur WD Red
## bash ##

# Identifier vos disques
lsblk
# Supposons : sdb, sdc, sdd = vos 3 WD Red

# Option A : LVM (Simple et flexible)
sudo pvcreate /dev/sdb /dev/sdc /dev/sdd
sudo vgcreate vg-data-ai /dev/sdb /dev/sdc /dev/sdd
sudo lvcreate -L 500G -n lv-datasets vg-data-ai
sudo lvcreate -L 500G -n lv-models vg-data-ai

# Formater
sudo mkfs.ext4 /dev/vg-data-ai/lv-datasets
sudo mkfs.ext4 /dev/vg-data-ai/lv-models

# Monter sur l'hôte
sudo mkdir -p /mnt/ai-storage/{datasets,models}
sudo mount /dev/vg-data-ai/lv-datasets /mnt/ai-storage/datasets
sudo mount /dev/vg-data-ai/lv-models /mnt/ai-storage/models

# Rendre permanent
echo '/dev/vg-data-ai/lv-datasets /mnt/ai-storage/datasets ext4 defaults 0 2' | sudo tee -a /etc/fstab
echo '/dev/vg-data-ai/lv-models /mnt/ai-storage/models ext4 defaults 0 2' | sudo tee -a /etc/fstab

## ##








